{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d5fc802b-cd86-42ab-9e76-57c94ba38105",
   "metadata": {},
   "source": [
    "!pip install transformers \n",
    "!pip install datasets\n",
    "!pip install torch\n",
    "!pip install huggingface_hub\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f67d1c-5851-477e-ba76-3a76da2ed39f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2da84ebf-5b00-41e2-ad49-6ef0196f2c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spm.model from cache at /home/sammartj/.cache/huggingface/hub/models--Clinical-AI-Apollo--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/spm.model\n",
      "loading file tokenizer.json from cache at /home/sammartj/.cache/huggingface/hub/models--Clinical-AI-Apollo--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/tokenizer.json\n",
      "loading file added_tokens.json from cache at /home/sammartj/.cache/huggingface/hub/models--Clinical-AI-Apollo--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/added_tokens.json\n",
      "loading file special_tokens_map.json from cache at /home/sammartj/.cache/huggingface/hub/models--Clinical-AI-Apollo--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/sammartj/.cache/huggingface/hub/models--Clinical-AI-Apollo--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/sammartj/.cache/huggingface/hub/models--Clinical-AI-Apollo--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"Clinical-AI-Apollo/Medical-NER\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-ACTIVITY\",\n",
      "    \"2\": \"I-ACTIVITY\",\n",
      "    \"3\": \"I-ADMINISTRATION\",\n",
      "    \"4\": \"B-ADMINISTRATION\",\n",
      "    \"5\": \"B-AGE\",\n",
      "    \"6\": \"I-AGE\",\n",
      "    \"7\": \"I-AREA\",\n",
      "    \"8\": \"B-AREA\",\n",
      "    \"9\": \"B-BIOLOGICAL_ATTRIBUTE\",\n",
      "    \"10\": \"I-BIOLOGICAL_ATTRIBUTE\",\n",
      "    \"11\": \"I-BIOLOGICAL_STRUCTURE\",\n",
      "    \"12\": \"B-BIOLOGICAL_STRUCTURE\",\n",
      "    \"13\": \"B-CLINICAL_EVENT\",\n",
      "    \"14\": \"I-CLINICAL_EVENT\",\n",
      "    \"15\": \"B-COLOR\",\n",
      "    \"16\": \"I-COLOR\",\n",
      "    \"17\": \"I-COREFERENCE\",\n",
      "    \"18\": \"B-COREFERENCE\",\n",
      "    \"19\": \"B-DATE\",\n",
      "    \"20\": \"I-DATE\",\n",
      "    \"21\": \"I-DETAILED_DESCRIPTION\",\n",
      "    \"22\": \"B-DETAILED_DESCRIPTION\",\n",
      "    \"23\": \"I-DIAGNOSTIC_PROCEDURE\",\n",
      "    \"24\": \"B-DIAGNOSTIC_PROCEDURE\",\n",
      "    \"25\": \"I-DISEASE_DISORDER\",\n",
      "    \"26\": \"B-DISEASE_DISORDER\",\n",
      "    \"27\": \"B-DISTANCE\",\n",
      "    \"28\": \"I-DISTANCE\",\n",
      "    \"29\": \"B-DOSAGE\",\n",
      "    \"30\": \"I-DOSAGE\",\n",
      "    \"31\": \"I-DURATION\",\n",
      "    \"32\": \"B-DURATION\",\n",
      "    \"33\": \"I-FAMILY_HISTORY\",\n",
      "    \"34\": \"B-FAMILY_HISTORY\",\n",
      "    \"35\": \"B-FREQUENCY\",\n",
      "    \"36\": \"I-FREQUENCY\",\n",
      "    \"37\": \"I-HEIGHT\",\n",
      "    \"38\": \"B-HEIGHT\",\n",
      "    \"39\": \"B-HISTORY\",\n",
      "    \"40\": \"I-HISTORY\",\n",
      "    \"41\": \"I-LAB_VALUE\",\n",
      "    \"42\": \"B-LAB_VALUE\",\n",
      "    \"43\": \"I-MASS\",\n",
      "    \"44\": \"B-MASS\",\n",
      "    \"45\": \"I-MEDICATION\",\n",
      "    \"46\": \"B-MEDICATION\",\n",
      "    \"47\": \"I-NONBIOLOGICAL_LOCATION\",\n",
      "    \"48\": \"B-NONBIOLOGICAL_LOCATION\",\n",
      "    \"49\": \"I-OCCUPATION\",\n",
      "    \"50\": \"B-OCCUPATION\",\n",
      "    \"51\": \"B-OTHER_ENTITY\",\n",
      "    \"52\": \"I-OTHER_ENTITY\",\n",
      "    \"53\": \"B-OTHER_EVENT\",\n",
      "    \"54\": \"I-OTHER_EVENT\",\n",
      "    \"55\": \"I-OUTCOME\",\n",
      "    \"56\": \"B-OUTCOME\",\n",
      "    \"57\": \"I-PERSONAL_BACKGROUND\",\n",
      "    \"58\": \"B-PERSONAL_BACKGROUND\",\n",
      "    \"59\": \"B-QUALITATIVE_CONCEPT\",\n",
      "    \"60\": \"I-QUALITATIVE_CONCEPT\",\n",
      "    \"61\": \"I-QUANTITATIVE_CONCEPT\",\n",
      "    \"62\": \"B-QUANTITATIVE_CONCEPT\",\n",
      "    \"63\": \"B-SEVERITY\",\n",
      "    \"64\": \"I-SEVERITY\",\n",
      "    \"65\": \"B-SEX\",\n",
      "    \"66\": \"I-SEX\",\n",
      "    \"67\": \"B-SHAPE\",\n",
      "    \"68\": \"I-SHAPE\",\n",
      "    \"69\": \"B-SIGN_SYMPTOM\",\n",
      "    \"70\": \"I-SIGN_SYMPTOM\",\n",
      "    \"71\": \"B-SUBJECT\",\n",
      "    \"72\": \"I-SUBJECT\",\n",
      "    \"73\": \"B-TEXTURE\",\n",
      "    \"74\": \"I-TEXTURE\",\n",
      "    \"75\": \"B-THERAPEUTIC_PROCEDURE\",\n",
      "    \"76\": \"I-THERAPEUTIC_PROCEDURE\",\n",
      "    \"77\": \"I-TIME\",\n",
      "    \"78\": \"B-TIME\",\n",
      "    \"79\": \"B-VOLUME\",\n",
      "    \"80\": \"I-VOLUME\",\n",
      "    \"81\": \"I-WEIGHT\",\n",
      "    \"82\": \"B-WEIGHT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-ACTIVITY\": 1,\n",
      "    \"B-ADMINISTRATION\": 4,\n",
      "    \"B-AGE\": 5,\n",
      "    \"B-AREA\": 8,\n",
      "    \"B-BIOLOGICAL_ATTRIBUTE\": 9,\n",
      "    \"B-BIOLOGICAL_STRUCTURE\": 12,\n",
      "    \"B-CLINICAL_EVENT\": 13,\n",
      "    \"B-COLOR\": 15,\n",
      "    \"B-COREFERENCE\": 18,\n",
      "    \"B-DATE\": 19,\n",
      "    \"B-DETAILED_DESCRIPTION\": 22,\n",
      "    \"B-DIAGNOSTIC_PROCEDURE\": 24,\n",
      "    \"B-DISEASE_DISORDER\": 26,\n",
      "    \"B-DISTANCE\": 27,\n",
      "    \"B-DOSAGE\": 29,\n",
      "    \"B-DURATION\": 32,\n",
      "    \"B-FAMILY_HISTORY\": 34,\n",
      "    \"B-FREQUENCY\": 35,\n",
      "    \"B-HEIGHT\": 38,\n",
      "    \"B-HISTORY\": 39,\n",
      "    \"B-LAB_VALUE\": 42,\n",
      "    \"B-MASS\": 44,\n",
      "    \"B-MEDICATION\": 46,\n",
      "    \"B-NONBIOLOGICAL_LOCATION\": 48,\n",
      "    \"B-OCCUPATION\": 50,\n",
      "    \"B-OTHER_ENTITY\": 51,\n",
      "    \"B-OTHER_EVENT\": 53,\n",
      "    \"B-OUTCOME\": 56,\n",
      "    \"B-PERSONAL_BACKGROUND\": 58,\n",
      "    \"B-QUALITATIVE_CONCEPT\": 59,\n",
      "    \"B-QUANTITATIVE_CONCEPT\": 62,\n",
      "    \"B-SEVERITY\": 63,\n",
      "    \"B-SEX\": 65,\n",
      "    \"B-SHAPE\": 67,\n",
      "    \"B-SIGN_SYMPTOM\": 69,\n",
      "    \"B-SUBJECT\": 71,\n",
      "    \"B-TEXTURE\": 73,\n",
      "    \"B-THERAPEUTIC_PROCEDURE\": 75,\n",
      "    \"B-TIME\": 78,\n",
      "    \"B-VOLUME\": 79,\n",
      "    \"B-WEIGHT\": 82,\n",
      "    \"I-ACTIVITY\": 2,\n",
      "    \"I-ADMINISTRATION\": 3,\n",
      "    \"I-AGE\": 6,\n",
      "    \"I-AREA\": 7,\n",
      "    \"I-BIOLOGICAL_ATTRIBUTE\": 10,\n",
      "    \"I-BIOLOGICAL_STRUCTURE\": 11,\n",
      "    \"I-CLINICAL_EVENT\": 14,\n",
      "    \"I-COLOR\": 16,\n",
      "    \"I-COREFERENCE\": 17,\n",
      "    \"I-DATE\": 20,\n",
      "    \"I-DETAILED_DESCRIPTION\": 21,\n",
      "    \"I-DIAGNOSTIC_PROCEDURE\": 23,\n",
      "    \"I-DISEASE_DISORDER\": 25,\n",
      "    \"I-DISTANCE\": 28,\n",
      "    \"I-DOSAGE\": 30,\n",
      "    \"I-DURATION\": 31,\n",
      "    \"I-FAMILY_HISTORY\": 33,\n",
      "    \"I-FREQUENCY\": 36,\n",
      "    \"I-HEIGHT\": 37,\n",
      "    \"I-HISTORY\": 40,\n",
      "    \"I-LAB_VALUE\": 41,\n",
      "    \"I-MASS\": 43,\n",
      "    \"I-MEDICATION\": 45,\n",
      "    \"I-NONBIOLOGICAL_LOCATION\": 47,\n",
      "    \"I-OCCUPATION\": 49,\n",
      "    \"I-OTHER_ENTITY\": 52,\n",
      "    \"I-OTHER_EVENT\": 54,\n",
      "    \"I-OUTCOME\": 55,\n",
      "    \"I-PERSONAL_BACKGROUND\": 57,\n",
      "    \"I-QUALITATIVE_CONCEPT\": 60,\n",
      "    \"I-QUANTITATIVE_CONCEPT\": 61,\n",
      "    \"I-SEVERITY\": 64,\n",
      "    \"I-SEX\": 66,\n",
      "    \"I-SHAPE\": 68,\n",
      "    \"I-SIGN_SYMPTOM\": 70,\n",
      "    \"I-SUBJECT\": 72,\n",
      "    \"I-TEXTURE\": 74,\n",
      "    \"I-THERAPEUTIC_PROCEDURE\": 76,\n",
      "    \"I-TIME\": 77,\n",
      "    \"I-VOLUME\": 80,\n",
      "    \"I-WEIGHT\": 81,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/sammartj/.cache/huggingface/hub/models--Clinical-AI-Apollo--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/model.safetensors\n",
      "All model checkpoint weights were used when initializing DebertaV2ForTokenClassification.\n",
      "\n",
      "All the weights of DebertaV2ForTokenClassification were initialized from the model checkpoint at Clinical-AI-Apollo/Medical-NER.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-ACTIVITY', 2: 'I-ACTIVITY', 3: 'I-ADMINISTRATION', 4: 'B-ADMINISTRATION', 5: 'B-AGE', 6: 'I-AGE', 7: 'I-AREA', 8: 'B-AREA', 9: 'B-BIOLOGICAL_ATTRIBUTE', 10: 'I-BIOLOGICAL_ATTRIBUTE', 11: 'I-BIOLOGICAL_STRUCTURE', 12: 'B-BIOLOGICAL_STRUCTURE', 13: 'B-CLINICAL_EVENT', 14: 'I-CLINICAL_EVENT', 15: 'B-COLOR', 16: 'I-COLOR', 17: 'I-COREFERENCE', 18: 'B-COREFERENCE', 19: 'B-DATE', 20: 'I-DATE', 21: 'I-DETAILED_DESCRIPTION', 22: 'B-DETAILED_DESCRIPTION', 23: 'I-DIAGNOSTIC_PROCEDURE', 24: 'B-DIAGNOSTIC_PROCEDURE', 25: 'I-DISEASE_DISORDER', 26: 'B-DISEASE_DISORDER', 27: 'B-DISTANCE', 28: 'I-DISTANCE', 29: 'B-DOSAGE', 30: 'I-DOSAGE', 31: 'I-DURATION', 32: 'B-DURATION', 33: 'I-FAMILY_HISTORY', 34: 'B-FAMILY_HISTORY', 35: 'B-FREQUENCY', 36: 'I-FREQUENCY', 37: 'I-HEIGHT', 38: 'B-HEIGHT', 39: 'B-HISTORY', 40: 'I-HISTORY', 41: 'I-LAB_VALUE', 42: 'B-LAB_VALUE', 43: 'I-MASS', 44: 'B-MASS', 45: 'I-MEDICATION', 46: 'B-MEDICATION', 47: 'I-NONBIOLOGICAL_LOCATION', 48: 'B-NONBIOLOGICAL_LOCATION', 49: 'I-OCCUPATION', 50: 'B-OCCUPATION', 51: 'B-OTHER_ENTITY', 52: 'I-OTHER_ENTITY', 53: 'B-OTHER_EVENT', 54: 'I-OTHER_EVENT', 55: 'I-OUTCOME', 56: 'B-OUTCOME', 57: 'I-PERSONAL_BACKGROUND', 58: 'B-PERSONAL_BACKGROUND', 59: 'B-QUALITATIVE_CONCEPT', 60: 'I-QUALITATIVE_CONCEPT', 61: 'I-QUANTITATIVE_CONCEPT', 62: 'B-QUANTITATIVE_CONCEPT', 63: 'B-SEVERITY', 64: 'I-SEVERITY', 65: 'B-SEX', 66: 'I-SEX', 67: 'B-SHAPE', 68: 'I-SHAPE', 69: 'B-SIGN_SYMPTOM', 70: 'I-SIGN_SYMPTOM', 71: 'B-SUBJECT', 72: 'I-SUBJECT', 73: 'B-TEXTURE', 74: 'I-TEXTURE', 75: 'B-THERAPEUTIC_PROCEDURE', 76: 'I-THERAPEUTIC_PROCEDURE', 77: 'I-TIME', 78: 'B-TIME', 79: 'B-VOLUME', 80: 'I-VOLUME', 81: 'I-WEIGHT', 82: 'B-WEIGHT'}\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "print(model.config.id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2acb87f6-321a-4cce-bced-71e243ab6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = {\n",
    "    83 : \"B-PROTEIN\",\n",
    "    84 : \"I-PROTEIN\",\n",
    "    85 : \"B-GENE\",\n",
    "    86 : \"I-GENE\"\n",
    "}\n",
    "existing_labels = model.config.id2label\n",
    "\n",
    "updated_labels = {**existing_labels, **new_tags}\n",
    "\n",
    "# Update model's config\n",
    "model.config.id2label = updated_labels\n",
    "model.config.label2id = {v: k for k, v in updated_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "82299adc-74f1-40d0-98c5-24018ca00c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "num_labels = 87  # 83 original + 4 new entities\n",
    "model.classifier = nn.Linear(in_features=model.config.hidden_size, out_features=num_labels)\n",
    "\n",
    "# Update model config to reflect new number of labels\n",
    "model.config.num_labels = num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82f1df44-5e4b-4cd8-ac08-959a45026105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in updated_model/config.json\n",
      "Model weights saved in updated_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"updated_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eaa2c818-7675-4bd0-a3d1-cd2e85b95312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file updated_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"updated_model\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-ACTIVITY\",\n",
      "    \"2\": \"I-ACTIVITY\",\n",
      "    \"3\": \"I-ADMINISTRATION\",\n",
      "    \"4\": \"B-ADMINISTRATION\",\n",
      "    \"5\": \"B-AGE\",\n",
      "    \"6\": \"I-AGE\",\n",
      "    \"7\": \"I-AREA\",\n",
      "    \"8\": \"B-AREA\",\n",
      "    \"9\": \"B-BIOLOGICAL_ATTRIBUTE\",\n",
      "    \"10\": \"I-BIOLOGICAL_ATTRIBUTE\",\n",
      "    \"11\": \"I-BIOLOGICAL_STRUCTURE\",\n",
      "    \"12\": \"B-BIOLOGICAL_STRUCTURE\",\n",
      "    \"13\": \"B-CLINICAL_EVENT\",\n",
      "    \"14\": \"I-CLINICAL_EVENT\",\n",
      "    \"15\": \"B-COLOR\",\n",
      "    \"16\": \"I-COLOR\",\n",
      "    \"17\": \"I-COREFERENCE\",\n",
      "    \"18\": \"B-COREFERENCE\",\n",
      "    \"19\": \"B-DATE\",\n",
      "    \"20\": \"I-DATE\",\n",
      "    \"21\": \"I-DETAILED_DESCRIPTION\",\n",
      "    \"22\": \"B-DETAILED_DESCRIPTION\",\n",
      "    \"23\": \"I-DIAGNOSTIC_PROCEDURE\",\n",
      "    \"24\": \"B-DIAGNOSTIC_PROCEDURE\",\n",
      "    \"25\": \"I-DISEASE_DISORDER\",\n",
      "    \"26\": \"B-DISEASE_DISORDER\",\n",
      "    \"27\": \"B-DISTANCE\",\n",
      "    \"28\": \"I-DISTANCE\",\n",
      "    \"29\": \"B-DOSAGE\",\n",
      "    \"30\": \"I-DOSAGE\",\n",
      "    \"31\": \"I-DURATION\",\n",
      "    \"32\": \"B-DURATION\",\n",
      "    \"33\": \"I-FAMILY_HISTORY\",\n",
      "    \"34\": \"B-FAMILY_HISTORY\",\n",
      "    \"35\": \"B-FREQUENCY\",\n",
      "    \"36\": \"I-FREQUENCY\",\n",
      "    \"37\": \"I-HEIGHT\",\n",
      "    \"38\": \"B-HEIGHT\",\n",
      "    \"39\": \"B-HISTORY\",\n",
      "    \"40\": \"I-HISTORY\",\n",
      "    \"41\": \"I-LAB_VALUE\",\n",
      "    \"42\": \"B-LAB_VALUE\",\n",
      "    \"43\": \"I-MASS\",\n",
      "    \"44\": \"B-MASS\",\n",
      "    \"45\": \"I-MEDICATION\",\n",
      "    \"46\": \"B-MEDICATION\",\n",
      "    \"47\": \"I-NONBIOLOGICAL_LOCATION\",\n",
      "    \"48\": \"B-NONBIOLOGICAL_LOCATION\",\n",
      "    \"49\": \"I-OCCUPATION\",\n",
      "    \"50\": \"B-OCCUPATION\",\n",
      "    \"51\": \"B-OTHER_ENTITY\",\n",
      "    \"52\": \"I-OTHER_ENTITY\",\n",
      "    \"53\": \"B-OTHER_EVENT\",\n",
      "    \"54\": \"I-OTHER_EVENT\",\n",
      "    \"55\": \"I-OUTCOME\",\n",
      "    \"56\": \"B-OUTCOME\",\n",
      "    \"57\": \"I-PERSONAL_BACKGROUND\",\n",
      "    \"58\": \"B-PERSONAL_BACKGROUND\",\n",
      "    \"59\": \"B-QUALITATIVE_CONCEPT\",\n",
      "    \"60\": \"I-QUALITATIVE_CONCEPT\",\n",
      "    \"61\": \"I-QUANTITATIVE_CONCEPT\",\n",
      "    \"62\": \"B-QUANTITATIVE_CONCEPT\",\n",
      "    \"63\": \"B-SEVERITY\",\n",
      "    \"64\": \"I-SEVERITY\",\n",
      "    \"65\": \"B-SEX\",\n",
      "    \"66\": \"I-SEX\",\n",
      "    \"67\": \"B-SHAPE\",\n",
      "    \"68\": \"I-SHAPE\",\n",
      "    \"69\": \"B-SIGN_SYMPTOM\",\n",
      "    \"70\": \"I-SIGN_SYMPTOM\",\n",
      "    \"71\": \"B-SUBJECT\",\n",
      "    \"72\": \"I-SUBJECT\",\n",
      "    \"73\": \"B-TEXTURE\",\n",
      "    \"74\": \"I-TEXTURE\",\n",
      "    \"75\": \"B-THERAPEUTIC_PROCEDURE\",\n",
      "    \"76\": \"I-THERAPEUTIC_PROCEDURE\",\n",
      "    \"77\": \"I-TIME\",\n",
      "    \"78\": \"B-TIME\",\n",
      "    \"79\": \"B-VOLUME\",\n",
      "    \"80\": \"I-VOLUME\",\n",
      "    \"81\": \"I-WEIGHT\",\n",
      "    \"82\": \"B-WEIGHT\",\n",
      "    \"83\": \"B-PROTEIN\",\n",
      "    \"84\": \"I-PROTEIN\",\n",
      "    \"85\": \"B-GENE\",\n",
      "    \"86\": \"I-GENE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-ACTIVITY\": 1,\n",
      "    \"B-ADMINISTRATION\": 4,\n",
      "    \"B-AGE\": 5,\n",
      "    \"B-AREA\": 8,\n",
      "    \"B-BIOLOGICAL_ATTRIBUTE\": 9,\n",
      "    \"B-BIOLOGICAL_STRUCTURE\": 12,\n",
      "    \"B-CLINICAL_EVENT\": 13,\n",
      "    \"B-COLOR\": 15,\n",
      "    \"B-COREFERENCE\": 18,\n",
      "    \"B-DATE\": 19,\n",
      "    \"B-DETAILED_DESCRIPTION\": 22,\n",
      "    \"B-DIAGNOSTIC_PROCEDURE\": 24,\n",
      "    \"B-DISEASE_DISORDER\": 26,\n",
      "    \"B-DISTANCE\": 27,\n",
      "    \"B-DOSAGE\": 29,\n",
      "    \"B-DURATION\": 32,\n",
      "    \"B-FAMILY_HISTORY\": 34,\n",
      "    \"B-FREQUENCY\": 35,\n",
      "    \"B-GENE\": 85,\n",
      "    \"B-HEIGHT\": 38,\n",
      "    \"B-HISTORY\": 39,\n",
      "    \"B-LAB_VALUE\": 42,\n",
      "    \"B-MASS\": 44,\n",
      "    \"B-MEDICATION\": 46,\n",
      "    \"B-NONBIOLOGICAL_LOCATION\": 48,\n",
      "    \"B-OCCUPATION\": 50,\n",
      "    \"B-OTHER_ENTITY\": 51,\n",
      "    \"B-OTHER_EVENT\": 53,\n",
      "    \"B-OUTCOME\": 56,\n",
      "    \"B-PERSONAL_BACKGROUND\": 58,\n",
      "    \"B-PROTEIN\": 83,\n",
      "    \"B-QUALITATIVE_CONCEPT\": 59,\n",
      "    \"B-QUANTITATIVE_CONCEPT\": 62,\n",
      "    \"B-SEVERITY\": 63,\n",
      "    \"B-SEX\": 65,\n",
      "    \"B-SHAPE\": 67,\n",
      "    \"B-SIGN_SYMPTOM\": 69,\n",
      "    \"B-SUBJECT\": 71,\n",
      "    \"B-TEXTURE\": 73,\n",
      "    \"B-THERAPEUTIC_PROCEDURE\": 75,\n",
      "    \"B-TIME\": 78,\n",
      "    \"B-VOLUME\": 79,\n",
      "    \"B-WEIGHT\": 82,\n",
      "    \"I-ACTIVITY\": 2,\n",
      "    \"I-ADMINISTRATION\": 3,\n",
      "    \"I-AGE\": 6,\n",
      "    \"I-AREA\": 7,\n",
      "    \"I-BIOLOGICAL_ATTRIBUTE\": 10,\n",
      "    \"I-BIOLOGICAL_STRUCTURE\": 11,\n",
      "    \"I-CLINICAL_EVENT\": 14,\n",
      "    \"I-COLOR\": 16,\n",
      "    \"I-COREFERENCE\": 17,\n",
      "    \"I-DATE\": 20,\n",
      "    \"I-DETAILED_DESCRIPTION\": 21,\n",
      "    \"I-DIAGNOSTIC_PROCEDURE\": 23,\n",
      "    \"I-DISEASE_DISORDER\": 25,\n",
      "    \"I-DISTANCE\": 28,\n",
      "    \"I-DOSAGE\": 30,\n",
      "    \"I-DURATION\": 31,\n",
      "    \"I-FAMILY_HISTORY\": 33,\n",
      "    \"I-FREQUENCY\": 36,\n",
      "    \"I-GENE\": 86,\n",
      "    \"I-HEIGHT\": 37,\n",
      "    \"I-HISTORY\": 40,\n",
      "    \"I-LAB_VALUE\": 41,\n",
      "    \"I-MASS\": 43,\n",
      "    \"I-MEDICATION\": 45,\n",
      "    \"I-NONBIOLOGICAL_LOCATION\": 47,\n",
      "    \"I-OCCUPATION\": 49,\n",
      "    \"I-OTHER_ENTITY\": 52,\n",
      "    \"I-OTHER_EVENT\": 54,\n",
      "    \"I-OUTCOME\": 55,\n",
      "    \"I-PERSONAL_BACKGROUND\": 57,\n",
      "    \"I-PROTEIN\": 84,\n",
      "    \"I-QUALITATIVE_CONCEPT\": 60,\n",
      "    \"I-QUANTITATIVE_CONCEPT\": 61,\n",
      "    \"I-SEVERITY\": 64,\n",
      "    \"I-SEX\": 66,\n",
      "    \"I-SHAPE\": 68,\n",
      "    \"I-SIGN_SYMPTOM\": 70,\n",
      "    \"I-SUBJECT\": 72,\n",
      "    \"I-TEXTURE\": 74,\n",
      "    \"I-THERAPEUTIC_PROCEDURE\": 76,\n",
      "    \"I-TIME\": 77,\n",
      "    \"I-VOLUME\": 80,\n",
      "    \"I-WEIGHT\": 81,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file updated_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForTokenClassification.\n",
      "\n",
      "All the weights of DebertaV2ForTokenClassification were initialized from the model checkpoint at updated_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"updated_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04ab21bf-e536-48ee-9dfc-201e042c5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf55562-b85a-49ee-97dc-ac63497ceecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration testing-7fba87adafe2b0c7\n",
      "Found cached dataset json (/home/sammartj/.cache/huggingface/datasets/json/testing-7fba87adafe2b0c7/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134d44a5cc24b768d7610279bae4d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"../downloaded_txt_files/testing\", data_files={\"train\": \"training.json\", \"test\": \"testing.json\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe1437f-42e3-41cc-9621-2478da106aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb99b6e16e0409c9c1b0c83c4578868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4353d04e52164cd4a43cddbf28744ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, padding='max_length', max_length = 128, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:  \n",
    "                label_ids.append(-100)  # Ignore special tokens\n",
    "            elif word_id >= len(label):  # Ensure word_id is within label range\n",
    "                label_ids.append(-100)  \n",
    "            elif word_id != word_ids[word_id - 1]:  # Assign label only to the first subword\n",
    "                label_ids.append(label[word_id])\n",
    "            else:\n",
    "                label_ids.append(-100)  # Assign -100 to subword tokens\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels  # Add labels to the dataset\n",
    "    return tokenized_inputs\n",
    "   \n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a1e1f6fe-9f98-4c6b-a935-dde093cbb63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "# Define evaluation metric\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    true_predictions = [[model.config.id2label[p] for p, l in zip(pred, label) if l != -100] \n",
    "                        for pred, label in zip(predictions, labels)]\n",
    "    true_labels = [[model.config.id2label[l] for p, l in zip(pred, label) if l != -100] \n",
    "                   for pred, label in zip(predictions, labels)]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8261c08-67d6-4fb0-aa47-c403e920618f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02036657e3d14219be573fa22b63db44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c00c63fbe5c45bc89585852c197f726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/208 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_labels_to_tensor(example):\n",
    "    example[\"labels\"] = torch.tensor(example[\"labels\"], dtype=torch.long)\n",
    "    return example\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(convert_labels_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a348bf9b-98e9-4ecb-ab86-4f11fc691d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `DebertaV2ForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/home/sammartj/.local/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 105\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 70\n",
      "  Number of trainable parameters = 183898455\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 19:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.698400</td>\n",
       "      <td>0.827919</td>\n",
       "      <td>0.566061</td>\n",
       "      <td>0.652235</td>\n",
       "      <td>0.606100</td>\n",
       "      <td>0.843764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.966300</td>\n",
       "      <td>0.459125</td>\n",
       "      <td>0.675971</td>\n",
       "      <td>0.777933</td>\n",
       "      <td>0.723377</td>\n",
       "      <td>0.886988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.376611</td>\n",
       "      <td>0.816976</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.911301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.369659</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.878492</td>\n",
       "      <td>0.849426</td>\n",
       "      <td>0.906799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.367208</td>\n",
       "      <td>0.836436</td>\n",
       "      <td>0.878492</td>\n",
       "      <td>0.856948</td>\n",
       "      <td>0.911751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `DebertaV2ForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 208\n",
      "  Batch size = 8\n",
      "/home/sammartj/.local/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./ner_results/checkpoint-14\n",
      "Configuration saved in ./ner_results/checkpoint-14/config.json\n",
      "Model weights saved in ./ner_results/checkpoint-14/pytorch_model.bin\n",
      "tokenizer config file saved in ./ner_results/checkpoint-14/tokenizer_config.json\n",
      "Special tokens file saved in ./ner_results/checkpoint-14/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `DebertaV2ForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 208\n",
      "  Batch size = 8\n",
      "/home/sammartj/.local/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./ner_results/checkpoint-28\n",
      "Configuration saved in ./ner_results/checkpoint-28/config.json\n",
      "Model weights saved in ./ner_results/checkpoint-28/pytorch_model.bin\n",
      "tokenizer config file saved in ./ner_results/checkpoint-28/tokenizer_config.json\n",
      "Special tokens file saved in ./ner_results/checkpoint-28/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `DebertaV2ForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 208\n",
      "  Batch size = 8\n",
      "/home/sammartj/.local/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./ner_results/checkpoint-42\n",
      "Configuration saved in ./ner_results/checkpoint-42/config.json\n",
      "Model weights saved in ./ner_results/checkpoint-42/pytorch_model.bin\n",
      "tokenizer config file saved in ./ner_results/checkpoint-42/tokenizer_config.json\n",
      "Special tokens file saved in ./ner_results/checkpoint-42/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `DebertaV2ForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 208\n",
      "  Batch size = 8\n",
      "/home/sammartj/.local/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./ner_results/checkpoint-56\n",
      "Configuration saved in ./ner_results/checkpoint-56/config.json\n",
      "Model weights saved in ./ner_results/checkpoint-56/pytorch_model.bin\n",
      "tokenizer config file saved in ./ner_results/checkpoint-56/tokenizer_config.json\n",
      "Special tokens file saved in ./ner_results/checkpoint-56/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `DebertaV2ForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 208\n",
      "  Batch size = 8\n",
      "/home/sammartj/.local/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./ner_results/checkpoint-70\n",
      "Configuration saved in ./ner_results/checkpoint-70/config.json\n",
      "Model weights saved in ./ner_results/checkpoint-70/pytorch_model.bin\n",
      "tokenizer config file saved in ./ner_results/checkpoint-70/tokenizer_config.json\n",
      "Special tokens file saved in ./ner_results/checkpoint-70/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=70, training_loss=0.6776569928441729, metrics={'train_runtime': 1187.1766, 'train_samples_per_second': 0.442, 'train_steps_per_second': 0.059, 'total_flos': 34322173804800.0, 'train_loss': 0.6776569928441729, 'epoch': 5.0})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d57bb5c-75e2-463c-835d-7bf73d415914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in finetuned-model/config.json\n",
      "Model weights saved in finetuned-model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"finetuned-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d4a45-e26b-47ba-bbab-9d563851b8dc",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65278b09-d441-40bd-9886-9bcfcf8c7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 18:45:39.255788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-01 18:45:39.809733: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 18:45:46.479389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-01 18:45:46.479649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-01 18:45:46.479659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "ner_model =  AutoModelForTokenClassification.from_pretrained(\"finetuned-model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1e4dcb-e794-44a9-a5af-c2d1157b49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "directory = Path('../downloaded_txt_files/target')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed62d54a-3e13-4cf8-b4d8-48724e57c9ff",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_token_class_ids = logits.argmax(-1)\n",
    "\n",
    "predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n",
    "\n",
    "labels = predicted_token_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ec370e-d584-41e7-b22d-2d56d7ebc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, tokenizer, chunk_size=100, stride=20):\n",
    "    tokens = tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(tokens), chunk_size - stride):\n",
    "        chunk = tokens[i : i + chunk_size]\n",
    "        chunks.append(tokenizer.decode(chunk))  # Convert tokens back to text\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5454b45-0e19-4703-80ee-b77a574d4980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['pmcid', 'entity', 'score', 'index', 'word', 'start', 'end'])\n",
    "counter = 0 \n",
    "for file in directory.iterdir():\n",
    "    if file.suffix == '.txt':\n",
    "        with open(file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        chunks = chunk_text(content, tokenizer, chunk_size=100, stride=20)\n",
    "\n",
    "        # Process each chunk with NER\n",
    "        results = []\n",
    "        for chunk in chunks:\n",
    "            results.extend(ner_pipeline(chunk))\n",
    "            \n",
    "        specific = []\n",
    "        for obj in results:\n",
    "            if obj['score'] > 0.5:\n",
    "                specific.append(obj)\n",
    "                  \n",
    "        for obj in specific:\n",
    "            if obj['word'] not in df['word'].unique():\n",
    "                   df.loc[len(df.index)] = [file.name, obj['entity'], obj['score'], obj['index'], obj['word'], obj['start'], obj['end']]\n",
    "        counter+=1\n",
    "        if counter%100 == 0:\n",
    "            print(counter)\n",
    "                  \n",
    "df.to_csv('../ner_results.csv')\n",
    "print('all done !')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
